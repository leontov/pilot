<!-- Copyright (c) 2024 Кочуров Владислав Евгеньевич -->

# Contributing

Спасибо, что помогаете развивать Kolibri Ω. Ниже перечислены базовые правила, которые позволяют сохранять проект воспроизводимым.

## Тестирование

* Перед отправкой изменений запускайте необходимые юнит-тесты и интеграционные проверки.
* Для новых сценариев самообучения предусмотрен тест `test_kolibri_ai_iterations`, который строится командой `make test-kolibri-ai` (или через CMake-таргет `test_kolibri_ai_iterations`). Он обеспечивает детерминированный self-play и проверяет рост `average_reward` и `success_rate`.

## Обновление эталонных метрик

Тест `tests/test_kolibri_ai_iterations.c` использует массивы `MockIterationPlan.rewards` и `MockIterationPlan.effectiveness` как эталонные значения.

1. Если в результате доработок ожидания по метрикам изменились, сначала убедитесь, что рост остаётся монотонным (без регрессий по `average_reward`/`success_rate`).
2. Обновите значения массивов в тесте таким образом, чтобы они отражали новую детерминированную траекторию self-play либо записанную пользовательскую сессию.
3. Проверьте, что счётчик имитационного блокчейна (`MockBlockchain`) и число обработанных итераций (`plan.total`) синхронизированы с обновлёнными данными.
4. Повторно запустите `make test-kolibri-ai`, зафиксируйте изменения и опишите причины обновления метрик в описании коммита/PR.

Соблюдение этих правил гарантирует воспроизводимость и понятность эволюции эталонных метрик.
